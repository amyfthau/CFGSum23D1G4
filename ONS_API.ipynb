{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amyfthau/CFGSum23D1G4/blob/data_collection/ONS_API.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ONS API Data Retrieval Notebook\n",
        "\n",
        "\n",
        "This Jupyter Notebook demonstrates how to retrieve and analyse data from the Office for National Statistics (ONS) API using Python.\n",
        "\n",
        "While the ONS is currently in the process of adding some information into their API and are from having added all of its datasets onto the API, there are over 300 datasets on that page.\n",
        "\n",
        "The supporting API documentation is available on:\n",
        "\n",
        "https://digitalblog.ons.gov.uk/2021/02/15/how-to-access-data-from-the-ons-beta-api/\n",
        "\n",
        "Access to the API is free with no registration required. It returns data in a JSON format with some rate limits.\n",
        "\n",
        "This notebook makes retrieval more simple and intuitive.\n",
        "\n",
        "## Some Advantages of using the API\n",
        "1. Provides access to real-time and dynamically updated data. This is particularly useful for our datasets which are frequently updated. Therefore, by using the API, we can always get the most up-to-date figures by running the script rather than checking on the website\n",
        "2. The API also allows for automated data retrieval: APIs allow you to automate the process of data retrieval. This is especially advantageous for ongoing monitoring and analysis tasks.\n",
        "\n",
        "## Terminology\n",
        "Descriptions for some terms used within this API.\n",
        "\n",
        "1. Dataset:A grouping of data (editions) with shared dimensions, for example Sex, Age and Geography, and all published history of this group of data. The options in these dimensions can change over time leading to separate editions. For example: Population Estimates for UK, England and Wales, Scotland and Northern Ireland\n",
        "\n",
        "2. Edition: A subset of the dataset representing a specific time period. For some datasets this edition can contain all time periods (all historical data). The latest version of this is displayed by default. For example: Population Estimates for UK, England and Wales, Scotland and Northern Ireland Mid-2016\n",
        "\n",
        "3. Version: A specific instance of the edition at a point in time. New versions can be published as a result of corrections, revisions or new data becoming available.\n",
        "\n",
        "## Getting Started\n",
        "Follow these steps to get started with the notebook:\n",
        "\n",
        "Clone or download this repository to your local machine.\n",
        "\n",
        "Ensure you have the necessary Python packages installed. You can install them using the following command:\n",
        "\n",
        "`pip install pandas requests`\n",
        "\n",
        "Open the Jupyter Notebook `ONS_API_Data_Retrieval.ipynb` in your Jupyter environment.\n",
        "\n",
        "## Functions for Dataset Exploration\n",
        "\n",
        "Before extracting data from the ONS API, this notebook provides functions to explore available datasets, parameters, options, versions, and editions:\n",
        "\n",
        "1. Run the `retrieve_all_datasets` function to find a list of datasets and their IDs and their description.\n",
        "2. Declare the `dataset_id` variable with your desired dataset ID.\n",
        "3. Utilise the following functions to retrieve relevant editions, versions, parameters, and options for your chosen `dataset_id` (there are some prespecified dataset_ids). These functions will also display information about the available parameters and their corresponding options, tailored to your specific `dataset_id`. This exploration is crucial for constructing precise data queries.\n",
        "\n",
        "The exploration functions include:\n",
        "\n",
        "### Retrieving Dataset Information\n",
        "To retrieve a list of available datasets along with their descriptions, use the `retrieve_all_datasets` function.\n",
        "\n",
        "### Finding Available Editions\n",
        "You can find available editions for a specific dataset using the `get_ONS_API_editions`\n",
        "\n",
        "### Finding the Latest Version\n",
        "To get the latest version of a dataset, use the `get_ONS_API_latest_ver function`\n",
        "\n",
        "### Exploring Parameters and Options\n",
        "To explore available parameters and their corresponding options for a specific dataset, version, and edition, use the `get_ONS_API_param_info function`\n",
        "\n",
        "## Data Retrieval\n",
        "\n",
        "After retrieving and storing editions:\n",
        "\n",
        "1. Set the base URL for the ONS API\n",
        "2. Define query parameters to retrieve data based on the functions above eg. for life expectancy:\n",
        "\n",
        "```\n",
        "query_params = {\n",
        "    \"agegroups\": \"30-34\",\n",
        "    \"time\": \"*\",\n",
        "    \"sex\": \"female\",\n",
        "    \"geography\": \"E06000001\"\n",
        "}\n",
        "```\n",
        "3. Call the `retrieve_ONS_API_data` function to retrieve the data and store it in a Pandas.\n",
        "\n",
        "You can only use one wildcard *\n",
        "\n",
        "```\n",
        "ONS_API_life_exp = retrieve_ONS_API_data(dataset_id, ONS_base_url, query_params, latest_version, available_edition)\n",
        "```\n",
        "\n",
        "### Enhancements\n",
        "Feel free to enhance this notebook further by incorporating additional explanations, examples, or custom analysis based on your specific use case.\n"
      ],
      "metadata": {
        "id": "iQX-5RpFFGK7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Mount Google Drive and Change Directory**"
      ],
      "metadata": {
        "id": "ulbG-9hzjwoo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rulDLHo9jidu",
        "outputId": "58ad9916-8a91-436f-f6f1-5e2eff0f387f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "# Import relevant libraries to mount drive\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Mount google drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define the path to your specific folder\n",
        "specific_folder_path = '/content/drive/MyDrive/CFGdegree_Sum23_D1_G4'\n",
        "\n",
        "# Navigate to the specific folder\n",
        "os.chdir(specific_folder_path)\n",
        "\n",
        "# change directory to shared group folder\n",
        "%cd /content/drive/MyDrive/CFGdegree_Sum23_D1_G4\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYgaxupnW4-A",
        "outputId": "1df5a583-cb0c-4cc1-8a38-120dbc2c43e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import Relevant Libraries**"
      ],
      "metadata": {
        "id": "KN9KL7CCj17J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import pandas\n",
        "import pandas as pd\n",
        "# Import requests\n",
        "import requests\n",
        "# # Import unittest\n",
        "# import unittest\n",
        "# Import date class from datetime module\n",
        "from datetime import date\n"
      ],
      "metadata": {
        "id": "DPZVaGqoj1rc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Functions**:\n",
        "\n",
        "Comprehensive script for interacting with the ONS API to retrieve dataset information, editions, versions, parameters, and options.\n",
        "\n",
        "The script will allow us to:\n",
        "\n",
        "* Check API access and retrieve dataset information.\n",
        "* Get available editions for a dataset.\n",
        "* Retrieve the latest version of a dataset.\n",
        "* Retrieve parameter information and options for a specific version of a dataset.\n",
        "* and show the list of datasets available: there is a function to download a csv file (see Drive) of the dataset IDs, and then the rest of the functions allow us to automatically go to the latest version's endpoint and provide a set of parameters and options for this."
      ],
      "metadata": {
        "id": "YeB-PdLt31dY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the base URL\n",
        "ONS_base_url = \"https://api.beta.ons.gov.uk/v1\"\n",
        "\n",
        "# Function to retrieve all datasets and their descriptions\n",
        "def retrieve_all_datasets(ONS_base_url):\n",
        "    \"\"\"\n",
        "    Retrieve all available datasets from the ONS API along with their descriptions.\n",
        "\n",
        "    Args:\n",
        "        ONS_base_url (str): The API base URL.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A DataFrame containing dataset information (id, description).\n",
        "    \"\"\"\n",
        "    # Call the function to check API access\n",
        "    request_success_ONS_api(ONS_base_url)\n",
        "\n",
        "    datasets = []\n",
        "\n",
        "    # Initialize pagination parameters\n",
        "    limit = 1000\n",
        "    offset = 0\n",
        "\n",
        "    while True:\n",
        "        # Set endpoint with pagination parameters\n",
        "        ONS_endpoint = f\"/datasets?limit={limit}&offset={offset}\"\n",
        "\n",
        "        # Retrieve list of datasets / send GET request to the specified API endpoint\n",
        "        response = requests.get(ONS_base_url + ONS_endpoint)\n",
        "\n",
        "        # Check if the request was successful (HTTP status code = 200 if successful)\n",
        "        if response.status_code == 200:\n",
        "            # Change response to JSON format\n",
        "            data = response.json()\n",
        "            # Extract the \"items\" field from the JSON\n",
        "            items = data.get(\"items\", [])\n",
        "            datasets.extend(items)\n",
        "\n",
        "            # If we have reached the end of the list, break the loop\n",
        "            if len(items) < limit:\n",
        "                break\n",
        "\n",
        "            # Increment offset for the next page\n",
        "            offset += limit\n",
        "        else:\n",
        "            print('Request for dataset information failed with status code:', response.status_code)\n",
        "            break\n",
        "\n",
        "    # Create a list of dictionaries with id and description\n",
        "    dataset_info = [{\"id\": item[\"id\"], \"description\": item[\"description\"]} for item in datasets]\n",
        "\n",
        "    # Convert the list of dictionaries into a Pandas DataFrame\n",
        "    datasets_df = pd.DataFrame(dataset_info)\n",
        "    return datasets_df\n",
        "\n",
        "\n",
        "# Create function to check API access\n",
        "def request_success_ONS_api(ONS_base_url):\n",
        "    \"\"\"\n",
        "    Check if the API request is successful and return the response data.\n",
        "\n",
        "    Args:\n",
        "        ONS_base_url (str): The base URL of the ONS API.\n",
        "\n",
        "    Returns:\n",
        "        dict: The response data as a dictionary, or an empty dictionary if the request failed.\n",
        "    \"\"\"\n",
        "    # Initialize the response data dictionary\n",
        "    ONS_data_response = {}\n",
        "\n",
        "    # Request data from the URL\n",
        "    response = requests.get(ONS_base_url)\n",
        "\n",
        "    # Check if the request was successful (HTTP status code = 200 if successful)\n",
        "    if response.status_code == 200:\n",
        "        # Convert response to JSON (dictionary)\n",
        "        ONS_data_response = response.json()\n",
        "        print(f\"Request success with status code: {response.status_code}\")\n",
        "    else:\n",
        "        print('Request failed with status code:', response.status_code)\n",
        "\n",
        "    return ONS_data_response\n",
        "\n",
        "# Create function to access first <limit> number of datasets available on ONS\n",
        "def retrieve_ONS_API_datasets_desc(ONS_base_url, limit):\n",
        "    \"\"\"\n",
        "    Retrieve dataset information from the ONS API and create a Pandas DataFrame.\n",
        "\n",
        "    Args:\n",
        "        ONS_base_url (str): The API base URL.\n",
        "        limit (int): The number of datset id and descriptions to view. Maximum is 1000\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A DataFrame containing dataset information (id, description).\n",
        "    \"\"\"\n",
        "    # Call the function to check API access\n",
        "    request_success_ONS_api(ONS_base_url)\n",
        "\n",
        "    # Set endpoint to list of datasets available for API\n",
        "    ONS_endpoint = f\"/datasets?limit={limit}\"\n",
        "\n",
        "    # Retrieve list of datasets / send GET request to the specified API endpoint\n",
        "    response = requests.get(ONS_base_url + ONS_endpoint)\n",
        "\n",
        "    # Check if the request was successful (HTTP status code = 200 if successful)\n",
        "    if response.status_code == 200:\n",
        "        # Change response to JSON format\n",
        "        data = response.json()\n",
        "\n",
        "        # Extract the \"items\" field from the JSON\n",
        "        # The square brackets [] are used to provide a default value in case the key \"items\"\n",
        "        items = data.get(\"items\", [])\n",
        "\n",
        "        # Create list of dictionaries with \"id\" \"description\"\n",
        "        # (list of dictionaries is easily converted into a Pandas DataFrame)\n",
        "        dataset_info = [{\"id\": item[\"id\"], \"description\": item[\"description\"]} for item in items]\n",
        "\n",
        "        # Change list of dictionaries into a Pandas DataFrame\n",
        "        ONS_API_datasets_desc_df = pd.DataFrame(dataset_info)\n",
        "        return ONS_API_datasets_desc_df\n",
        "\n",
        "    else:\n",
        "        print('Request for dataset information failed with status code:', response.status_code)\n",
        "        return None\n",
        "\n",
        "# Create function to convert Pandas DataFrame into CSV files\n",
        "def save_df_to_csv(dataframe, file_name):\n",
        "    \"\"\"\n",
        "    Convert and save a Pandas DataFrame to a CSV file.\n",
        "\n",
        "    Args:\n",
        "        dataframe (pd.DataFrame): DataFrame to be saved.\n",
        "        file_name (str): Name of the CSV file\n",
        "\n",
        "    Returns:\n",
        "        csv_file (csv): \"ONS_API_available_datasets\"\n",
        "    \"\"\"\n",
        "    df = dataframe.to_csv(file_name, index=False)\n",
        "    print(f\"DataFrame saved as {file_name}.csv\")\n",
        "    return None\n",
        "\n",
        "# Create function to retrieve editions for an IDs\n",
        "def get_ONS_API_editions(dataset_id, ONS_base_url):\n",
        "    \"\"\"\n",
        "    Retrieve dataset editions from the ONS API and create a Pandas DataFrame.\n",
        "\n",
        "    Args:\n",
        "        dataset_id (str): the ID for the dataset to extract the available editions\n",
        "        ONS_base_url (str): The API base URL.\n",
        "\n",
        "    Returns:\n",
        "        edition (str): provides the latest edition number eg. `37`\n",
        "\n",
        "    Note: to see all editions, comment out `return edition` and\n",
        "    uncomment `return editions_df` and adjust the variable calling the edition\n",
        "\n",
        "    \"\"\"\n",
        "    # Call the function to check API access\n",
        "    request_success_ONS_api(ONS_base_url)\n",
        "\n",
        "    # Set endpoint to list of datasets available for API\n",
        "    ONS_endpoint = f\"/datasets/{dataset_id}/editions\"\n",
        "\n",
        "    # Retrieve list of datasets / send GET request to the specified API endpoint\n",
        "    response = requests.get(ONS_base_url + ONS_endpoint)\n",
        "\n",
        "    # Check if the request was successful (HTTP status code = 200 if successful)\n",
        "    if response.status_code == 200:\n",
        "        # Change response to JSON format\n",
        "        data = response.json()\n",
        "        # Extract the \"items\" field from the JSON\n",
        "        # The square brackets [] are used to provide a default value in case the key \"items\"\n",
        "        items = data[\"items\"]\n",
        "        # Extract edition\n",
        "        edition = [item[\"edition\"] for item in items]\n",
        "        # Put into Pandas DataFrame\n",
        "        editions_df = pd.DataFrame({\"Edition\": [edition]})\n",
        "        # Retrieve latest edition by getting last value in dataframe\n",
        "        edition = editions_df.iloc[-1][0]\n",
        "        # Convert to string\n",
        "        edition = str(edition[0])\n",
        "        # return editions_df\n",
        "        return edition\n",
        "    else:\n",
        "        print('Request for dataset information failed with status code:', response.status_code)\n",
        "        return None\n",
        "\n",
        "# Create function to retrieve latest version of database\n",
        "def get_ONS_API_latest_ver(dataset_id, ONS_base_url, edition):\n",
        "    \"\"\"\n",
        "    Retrieve dataset latest version of dataset from the ONS API and create a Pandas DataFrame.\n",
        "\n",
        "    Args:\n",
        "        dataset_id (str): the ID for the dataset to extract the latest version\n",
        "        ONS_base_url (str): The API base URL\n",
        "        edition (str): the version to use.\n",
        "\n",
        "    Returns:\n",
        "        latest version (int): the latest version of the dataset eg `time-series`\n",
        "    \"\"\"\n",
        "    # Call the function to check API access\n",
        "    request_success_ONS_api(ONS_base_url)\n",
        "\n",
        "    # Set endpoint to list of datasets available for API\n",
        "    ONS_endpoint = f\"/datasets/{dataset_id}/editions/{edition}\"\n",
        "\n",
        "    # Retrieve list of datasets / send GET request to the specified API endpoint\n",
        "    response = requests.get(ONS_base_url + ONS_endpoint)\n",
        "\n",
        "    # Check if the request was successful (HTTP status code = 200 if successful)\n",
        "    if response.status_code == 200:\n",
        "        # Change response to JSON format\n",
        "        data = response.json()\n",
        "        # Extract latest version\n",
        "        latest_version = data[\"links\"]['latest_version']['id']\n",
        "        # Put into Pandas DataFrame\n",
        "        latest_version_df = pd.DataFrame({\"Latest Version\": [latest_version]})\n",
        "        # Retrieve the latest version\n",
        "        latest_version = str(latest_version_df.iloc[0][0])\n",
        "        return latest_version\n",
        "    else:\n",
        "        print('Request for dataset information failed with status code:', response.status_code)\n",
        "        return None\n",
        "\n",
        "def get_ONS_API_options(dataset_id, latest_version, parameter, edition):\n",
        "    \"\"\"\n",
        "    Retrieve options for a specific parameter of a dataset from the ONS API.\n",
        "    This is used within the `get_ONS_API_param_info` function for each parameter\n",
        "\n",
        "    Args:\n",
        "        dataset_id (str): the ID for the dataset\n",
        "        latest_version (str): the latest version of the dataset\n",
        "        parameter (str): the name of the parameter for which to retrieve options\n",
        "        edition (str): the edition of the dataset.\n",
        "\n",
        "    Returns:\n",
        "        options: A list of options for the specified parameter\n",
        "\n",
        "        , or None if the request fails.\n",
        "    \"\"\"\n",
        "\n",
        "    # Call the function to check API access\n",
        "    request_success_ONS_api(ONS_base_url)\n",
        "\n",
        "    # Set endpoint to retrieve options for the specified parameter\n",
        "    ONS_endpoint = f\"/datasets/{dataset_id}/editions/{edition}/versions/{latest_version}/dimensions/{parameter}/options\"\n",
        "\n",
        "    # Retrieve options data / send GET request to the specified API endpoint\n",
        "    response = requests.get(ONS_base_url + ONS_endpoint)\n",
        "\n",
        "    # Check if the request was successful (HTTP status code = 200 if successful)\n",
        "    if response.status_code == 200:\n",
        "        # Change response to JSON format\n",
        "        data = response.json()\n",
        "        # Extract the \"items\" field from the JSON\n",
        "        options = [{\"option\": item[\"option\"], \"label\": item[\"label\"]} for item in data[\"items\"]]\n",
        "        return options\n",
        "    else:\n",
        "        print('Request for options information failed with status code:', response.status_code)\n",
        "        return None\n",
        "\n",
        "\n",
        "# Create function to retrieve parameters/dimensions and their corresponding options for an ID\n",
        "def get_ONS_API_param_info(dataset_id, ONS_base_url, latest_version):\n",
        "    \"\"\"\n",
        "    Retrieve dimension information for a specific version of a dataset from the ONS API and create a Pandas DataFrame.\n",
        "\n",
        "    Args:\n",
        "        dataset_id (str): the ID for the dataset\n",
        "        ONS_base_url (str): The API base URL.\n",
        "        latest_version (str): the version to use.\n",
        "\n",
        "    Returns:\n",
        "        ONS_endpoint (str): endpoint of the relevant dataset_id based on the latest versions and Edition\n",
        "                            this is useful if the function to retrieve observations does not work\n",
        "        options_df (pd.DataFrame): A DataFrame containing dimension information.\n",
        "\n",
        "        , or None if the request fails.\n",
        "\n",
        "    \"\"\"\n",
        "    # Call the function to check API access\n",
        "    request_success_ONS_api(ONS_base_url)\n",
        "\n",
        "    # Set endpoint to retrieve dimensions for the specified version\n",
        "    ONS_endpoint = f\"/datasets/{dataset_id}/editions/{edition}/versions/{latest_version}/dimensions\"\n",
        "\n",
        "    # Retrieve dimension data / send GET request to the specified API endpoint\n",
        "    response = requests.get(ONS_base_url + ONS_endpoint)\n",
        "\n",
        "    # Check if the request was successful (HTTP status code = 200 if successful)\n",
        "    if response.status_code == 200:\n",
        "        # Change response to JSON format\n",
        "        data = response.json()\n",
        "        # Extract the \"items\" field from the JSON\n",
        "        items = data[\"items\"]\n",
        "        # Loop through all items to get params\n",
        "        params = [item[\"name\"] for item in items]\n",
        "        # Create an empty list to store options for each parameter\n",
        "        options_list = []\n",
        "        # Loop through each parameter to get options\n",
        "        for param in params:\n",
        "            options = get_ONS_API_options(dataset_id, latest_version, param, edition)\n",
        "            options_list.append(options)\n",
        "        # Put into Pandas DataFrame\n",
        "        options_df = pd.DataFrame({\"Parameters\": params, \"Options\": options_list})\n",
        "        return ONS_endpoint, options_df\n",
        "    else:\n",
        "        print('Request for dimension information failed with status code:', response.status_code)\n",
        "        return None\n",
        "\n",
        "def get_dataset_description(ONS_base_url, dataset_id):\n",
        "    \"\"\"\n",
        "    Retrieve the description of a dataset from the ONS API.\n",
        "\n",
        "    Args:\n",
        "        ONS_base_url (str): The API base URL.\n",
        "        dataset_id (str): The ID of the dataset.\n",
        "\n",
        "    Returns:\n",
        "        str: The description of the dataset, or None if the request fails.\n",
        "    \"\"\"\n",
        "    # Call the function to check API access\n",
        "    request_success_ONS_api(ONS_base_url)\n",
        "\n",
        "    # Set endpoint to retrieve dataset information\n",
        "    ONS_endpoint = f\"/datasets/{dataset_id}\"\n",
        "\n",
        "    # Retrieve dataset information / send GET request to the specified API endpoint\n",
        "    response = requests.get(ONS_base_url + ONS_endpoint)\n",
        "\n",
        "    # Check if the request was successful (HTTP status code = 200 if successful)\n",
        "    if response.status_code == 200:\n",
        "        # Change response to JSON format\n",
        "        data = response.json()\n",
        "        # Extract and return the description\n",
        "        description = data.get(\"description\")\n",
        "        return description\n",
        "    else:\n",
        "        print('Request for dataset description failed with status code:', response.status_code)\n",
        "        return None\n",
        "\n",
        "\n",
        "# Function to retrieve data from ONS API\n",
        "def retrieve_ONS_API_data(dataset_id, ONS_base_url, query_params, version, edition):\n",
        "    \"\"\"\n",
        "    Retrieve data from the ONS API for a specific dataset, version, and edition, based on given query parameters.\n",
        "\n",
        "    Args:\n",
        "        dataset_id (str): The ID of the dataset to retrieve data from.\n",
        "        ONS_base_url (str): The base URL of the ONS API.\n",
        "        query_params (dict): Query parameters to filter the data request filled with strings\n",
        "        version (str): The version of the dataset.\n",
        "        edition (str): The edition of the dataset.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A DataFrame containing retrieved data (Date, Data).\n",
        "    \"\"\"\n",
        "    # Call the function to check API access\n",
        "    request_success_ONS_api(ONS_base_url)\n",
        "\n",
        "    # Set params for API request\n",
        "    query_params = query_params\n",
        "\n",
        "    # Construct the API request URL\n",
        "    ONS_endpoint = f\"/datasets/{dataset_id}/editions/{edition}/versions/{version}/observations\"\n",
        "\n",
        "    # Send GET request to the API endpoint\n",
        "    response = requests.get(ONS_base_url + ONS_endpoint, params=query_params)\n",
        "\n",
        "    # Create lists to store data\n",
        "    dates = []\n",
        "    data_values = []\n",
        "\n",
        "    # Process the response\n",
        "    if response.status_code == 200:\n",
        "        ONS_data_response = response.json()\n",
        "        observations = ONS_data_response[\"observations\"]\n",
        "\n",
        "        # for observation in observations:\n",
        "        #     date = observation['dimensions']['Time']['label']\n",
        "        #     data = observation['observation']\n",
        "        #     dates.append(date)\n",
        "        #     data_values.append(data)\n",
        "\n",
        "        for observation in observations:\n",
        "            # Check if 'Time' key exists, otherwise try 'time'\n",
        "            if 'Time' in observation['dimensions']:\n",
        "                date = observation['dimensions']['Time']['label']\n",
        "            elif 'time' in observation['dimensions']:\n",
        "                date = observation['dimensions']['time']['label']\n",
        "            else:\n",
        "                date = None\n",
        "            data = observation['observation']\n",
        "            dates.append(date)\n",
        "            data_values.append(data)\n",
        "\n",
        "\n",
        "        # Create a DataFrame\n",
        "        ONS_API_df = pd.DataFrame({'Date': dates, 'Data': data_values})\n",
        "        # Check if DataFrame is retrieved\n",
        "        if ONS_API_df is not None:\n",
        "          print(\"Retrieved data:\")\n",
        "          print(ONS_API_df)\n",
        "        # Return df\n",
        "        return ONS_API_df\n",
        "\n",
        "    else:\n",
        "        print('Request failed with status code:', response.status_code)\n",
        "        return None"
      ],
      "metadata": {
        "id": "6H9r8NjF0l2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Call functions to download into drive the available datasets**"
      ],
      "metadata": {
        "id": "Bckv13NjiSJw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set parameters\n",
        "# Set limit of datasets loaded\n",
        "limit = 1000\n",
        "# Set ONS base URL\n",
        "ONS_base_url = \"https://api.beta.ons.gov.uk/v1\"\n",
        "# Returns the current local date\n",
        "today = str(date.today())\n",
        "\n",
        "# Call function to retrieve datasets\n",
        "all_datasets_df = retrieve_all_datasets(ONS_base_url)\n",
        "\n",
        "# Call function to convert to CSV file\n",
        "save_df_to_csv(all_datasets_df, f\"ONS_API_available_datasets_{today}.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4YpHi7xiSWw",
        "outputId": "44ed83b6-cd02-49b4-8175-8b878fb6fa18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Request success with status code: 200\n",
            "DataFrame saved as ONS_API_available_datasets_2023-08-20.csv.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Call functions to show parameters, available options, versions, editions and data description etc for retrieval of data**\n",
        "\n",
        "Modify the dataset_id to the appropriate ID to check for parameters"
      ],
      "metadata": {
        "id": "7mHu05RtNYje"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set ID\n",
        "# dataset_id = \"cpih01\"\n",
        "# dataset_id = \"regional-gdp-by-quarter\"\n",
        "# dataset_id = \"house-prices-local-authority\"\n",
        "# dataset_id = \"gdp-to-four-decimal-places\"\n",
        "# dataset_id = \"weekly-deaths-region\"\n",
        "# dataset_id = \"retail-sales-index\"\n",
        "# dataset_id = \"online-job-advert-estimates\"\n",
        "dataset_id = \"life-expectancy-by-local-authority\"\n",
        "# dataset_id = \"house-prices-local-authority\" # starts from 2015\n",
        "# dataset_id = \"index-private-housing-rental-prices\" # only starts from dec-21\n",
        "# dataset_id = \"labour-market\" # unemployment indicator\n",
        "\n",
        "\n",
        "# A) Retrieve last editions\n",
        "edition = get_ONS_API_editions(dataset_id, ONS_base_url)\n",
        "\n",
        "# B) Retrieve latest version of dataset\n",
        "latest_version = get_ONS_API_latest_ver(dataset_id, ONS_base_url, edition)\n",
        "version = latest_version\n",
        "\n",
        "# C) Retrieve information around parameters\n",
        "ons_endpoint_result, options_df = get_ONS_API_param_info(dataset_id, ONS_base_url, latest_version)\n",
        "# print(options_df)\n",
        "\n",
        "# Print parameters and options\n",
        "for index, row in options_df.iterrows():\n",
        "    parameter = row[\"Parameters\"]\n",
        "    options = row[\"Options\"]\n",
        "\n",
        "    # Print the parameter name\n",
        "    print(f\"\\nParameter: {parameter}\")\n",
        "\n",
        "    # Loop through options for each parameter\n",
        "    for option in options:\n",
        "        option_name = option['option']\n",
        "        option_label = option['label']\n",
        "        # Indent and print each option and its label\n",
        "        print(f\"    ⟡ Option: '{option_name}', ⟡ Label: '{option_label}'\")\n",
        "\n",
        "    # Print a new line to separate parameters\n",
        "    print(\"\\n\")\n",
        "\n",
        "# D) Retrive dataset description\n",
        "description = get_dataset_description(ONS_base_url, dataset_id)\n",
        "\n",
        "# E) Print all results\n",
        "print(f\"**********\\nThis is information for dataset '{dataset_id}' \")\n",
        "print(f\"⟡ With the following description: {description}\")\n",
        "print(f\"⟡ The latest version of this dataset is '{version}'\")\n",
        "print(f\"⟡ The edition is: '{edition}'\")\n",
        "print(f\"⟡ The final endpoint is:'{ons_endpoint_result}'\")\n",
        "print(\"**********\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QtVNVUlnNGhn",
        "outputId": "ca2f6059-2709-4f62-e622-908abc9d30f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Request success with status code: 200\n",
            "Request success with status code: 200\n",
            "Request success with status code: 200\n",
            "Request success with status code: 200\n",
            "Request success with status code: 200\n",
            "Request success with status code: 200\n",
            "Request success with status code: 200\n",
            "\n",
            "Parameter: agegroups\n",
            "    ⟡ Option: '0-1', ⟡ Label: '00-01'\n",
            "    ⟡ Option: '1-4', ⟡ Label: '01-04'\n",
            "    ⟡ Option: '10-14', ⟡ Label: '10-14'\n",
            "    ⟡ Option: '15-19', ⟡ Label: '15-19'\n",
            "    ⟡ Option: '20-24', ⟡ Label: '20-24'\n",
            "    ⟡ Option: '25-29', ⟡ Label: '25-29'\n",
            "    ⟡ Option: '30-34', ⟡ Label: '30-34'\n",
            "    ⟡ Option: '35-39', ⟡ Label: '35-39'\n",
            "    ⟡ Option: '40-44', ⟡ Label: '40-44'\n",
            "    ⟡ Option: '45-49', ⟡ Label: '45-49'\n",
            "    ⟡ Option: '5-9', ⟡ Label: '05-09'\n",
            "    ⟡ Option: '50-54', ⟡ Label: '50-54'\n",
            "    ⟡ Option: '55-59', ⟡ Label: '55-59'\n",
            "    ⟡ Option: '60-64', ⟡ Label: '60-64'\n",
            "    ⟡ Option: '65-69', ⟡ Label: '65-69'\n",
            "    ⟡ Option: '70-74', ⟡ Label: '70-74'\n",
            "    ⟡ Option: '75-79', ⟡ Label: '75-79'\n",
            "    ⟡ Option: '80-84', ⟡ Label: '80-84'\n",
            "    ⟡ Option: '85-89', ⟡ Label: '85-89'\n",
            "    ⟡ Option: '90+', ⟡ Label: '90+'\n",
            "\n",
            "\n",
            "\n",
            "Parameter: geography\n",
            "    ⟡ Option: 'E06000001', ⟡ Label: 'Hartlepool'\n",
            "    ⟡ Option: 'E06000002', ⟡ Label: 'Middlesbrough'\n",
            "    ⟡ Option: 'E06000003', ⟡ Label: 'Redcar and Cleveland'\n",
            "    ⟡ Option: 'E06000004', ⟡ Label: 'Stockton-on-Tees'\n",
            "    ⟡ Option: 'E06000005', ⟡ Label: 'Darlington'\n",
            "    ⟡ Option: 'E06000006', ⟡ Label: 'Halton'\n",
            "    ⟡ Option: 'E06000007', ⟡ Label: 'Warrington'\n",
            "    ⟡ Option: 'E06000008', ⟡ Label: 'Blackburn with Darwen'\n",
            "    ⟡ Option: 'E06000009', ⟡ Label: 'Blackpool'\n",
            "    ⟡ Option: 'E06000010', ⟡ Label: 'Kingston upon Hull, City of'\n",
            "    ⟡ Option: 'E06000011', ⟡ Label: 'East Riding of Yorkshire'\n",
            "    ⟡ Option: 'E06000012', ⟡ Label: 'North East Lincolnshire'\n",
            "    ⟡ Option: 'E06000013', ⟡ Label: 'North Lincolnshire'\n",
            "    ⟡ Option: 'E06000014', ⟡ Label: 'York'\n",
            "    ⟡ Option: 'E06000015', ⟡ Label: 'Derby'\n",
            "    ⟡ Option: 'E06000016', ⟡ Label: 'Leicester'\n",
            "    ⟡ Option: 'E06000017', ⟡ Label: 'Rutland'\n",
            "    ⟡ Option: 'E06000018', ⟡ Label: 'Nottingham'\n",
            "    ⟡ Option: 'E06000019', ⟡ Label: 'Herefordshire, County of'\n",
            "    ⟡ Option: 'E06000020', ⟡ Label: 'Telford and Wrekin'\n",
            "\n",
            "\n",
            "\n",
            "Parameter: sex\n",
            "    ⟡ Option: 'female', ⟡ Label: 'Female'\n",
            "    ⟡ Option: 'male', ⟡ Label: 'Male'\n",
            "\n",
            "\n",
            "\n",
            "Parameter: time\n",
            "    ⟡ Option: '2001-03', ⟡ Label: '2001-03'\n",
            "    ⟡ Option: '2002-04', ⟡ Label: '2002-04'\n",
            "    ⟡ Option: '2003-05', ⟡ Label: '2003-05'\n",
            "    ⟡ Option: '2004-06', ⟡ Label: '2004-06'\n",
            "    ⟡ Option: '2005-07', ⟡ Label: '2005-07'\n",
            "    ⟡ Option: '2006-08', ⟡ Label: '2006-08'\n",
            "    ⟡ Option: '2007-09', ⟡ Label: '2007-09'\n",
            "    ⟡ Option: '2008-10', ⟡ Label: '2008-10'\n",
            "    ⟡ Option: '2009-11', ⟡ Label: '2009-11'\n",
            "    ⟡ Option: '2010-12', ⟡ Label: '2010-12'\n",
            "    ⟡ Option: '2011-13', ⟡ Label: '2011-13'\n",
            "    ⟡ Option: '2012-14', ⟡ Label: '2012-14'\n",
            "    ⟡ Option: '2013-15', ⟡ Label: '2013-15'\n",
            "    ⟡ Option: '2014-16', ⟡ Label: '2014-16'\n",
            "    ⟡ Option: '2015-17', ⟡ Label: '2015-17'\n",
            "    ⟡ Option: '2016-18', ⟡ Label: '2016-18'\n",
            "    ⟡ Option: '2017-19', ⟡ Label: '2017-19'\n",
            "\n",
            "\n",
            "Request success with status code: 200\n",
            "**********\n",
            "This is information for dataset 'life-expectancy-by-local-authority' \n",
            "⟡ With the following description: Subnational trends in the average number of years people will live beyond their current age measured by “period life expectancy”.\n",
            "⟡ The latest version of this dataset is '1'\n",
            "⟡ The edition is: 'time-series'\n",
            "⟡ The final endpoint is:'/datasets/life-expectancy-by-local-authority/editions/time-series/versions/1/dimensions'\n",
            "**********\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset_id)\n",
        "print(edition)\n",
        "print(version)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8GbpiQkgVmLC",
        "outputId": "e5a04994-248b-467a-e103-48f0d5b5ae66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "life-expectancy-by-local-authority\n",
            "time-series\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**`Retreive data for CPI** - run when dataset set as cpih01\n"
      ],
      "metadata": {
        "id": "fPWLiCiv-2Dm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the base URL\n",
        "ONS_base_url = \"https://api.beta.ons.gov.uk/v1\"\n",
        "\n",
        "# Assuming we are only going to get time series (based on the nature of the analysis)\n",
        "# We will set time to a wildcard to get all the data available over time\n",
        "query_params = {\n",
        "    \"geography\": \"K02000001\",\n",
        "    \"aggregate\": \"CP00\",\n",
        "    \"time\": \"*\"}\n",
        "\n",
        "\n",
        "# Call function to print pandas df\n",
        "ONS_API_CPI_df = retrieve_ONS_API_data(dataset_id, ONS_base_url, query_params, version, edition)\n",
        "# Convert Pandas DataFrame into CSV\n",
        "save_df_to_csv(ONS_API_CPI_df, \"CPIH.csv\")\n"
      ],
      "metadata": {
        "id": "Z3eh9Hji_LWa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "70ab210f-f113-4bd5-8b65-0dbf0cda25c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Request success with status code: 200\n",
            "Request failed with status code: 400\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-805e8656ae45>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mONS_API_CPI_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretrieve_ONS_API_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mONS_base_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medition\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Convert Pandas DataFrame into CSV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0msave_df_to_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mONS_API_CPI_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"CPIH.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-7-477d443cc718>\u001b[0m in \u001b[0;36msave_df_to_csv\u001b[0;34m(dataframe, file_name)\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mcsv_file\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"ONS_API_available_datasets\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \"\"\"\n\u001b[0;32m--> 138\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"DataFrame saved as {file_name}.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'to_csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Retreive data for GDP** - only run when dataset_id = \"regional-gdp-by-quarter\""
      ],
      "metadata": {
        "id": "wz5qBW-qK44F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define the base URL\n",
        "ONS_base_url = \"https://api.beta.ons.gov.uk/v1\"\n",
        "\n",
        "# Assuming we are only going to get time series (based on the nature of the analysis)\n",
        "# We will set time to a wildcard to get all the data available over time\n",
        "# england only\n",
        "query_params = {\n",
        "    \"geography\": \"UK0\",\n",
        "    \"growthrate\": \"grq\",\n",
        "    \"prices\" : \"cvm\",\n",
        "    \"time\": \"*\" ,\n",
        "    \"unofficialstandardindustrialclassification\": \"A--T\"}\n",
        "\n",
        "ONS_API_GDP_df = retrieve_ONS_API_data(dataset_id, ONS_base_url, query_params, version, edition)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-fxS-9UeK5Hd",
        "outputId": "38d1aca6-3fe9-41ab-ddf3-1a5ad66e8f97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Request success with status code: 200\n",
            "Request failed with status code: 400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Retreive data for GDP to 4 dp** - only run when dataset_id = \"gdp-to-four-decimal-places\""
      ],
      "metadata": {
        "id": "WDC8wirHt49m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define the base URL\n",
        "ONS_base_url = \"https://api.beta.ons.gov.uk/v1\"\n",
        "\n",
        "# Assuming we are only going to get time series (based on the nature of the analysis)\n",
        "# We will set time to a wildcard to get all the data available over time\n",
        "query_params = {\n",
        "    \"geography\": \"K02000001\",\n",
        "    \"unofficialstandardindustrialclassification\": \"A--T\",\n",
        "    \"time\": \"*\"}\n",
        "\n",
        "\n",
        "# Call function to print pandas df\n",
        "ONS_API_GDP_4_df = retrieve_ONS_API_data(dataset_id, ONS_base_url, query_params, version, edition)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ynbBKUoTt5RV",
        "outputId": "008ec6f3-1cd5-4d0d-b5d5-32a9855997c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Request success with status code: 200\n",
            "Request failed with status code: 400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**House Prices** dataset_id = \"house-prices-local-authority\"\n"
      ],
      "metadata": {
        "id": "S2Ch5BztO6vO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the base URL\n",
        "ONS_base_url = \"https://api.beta.ons.gov.uk/v1\"\n",
        "\n",
        "# Assuming we are only going to get time series (based on the nature of the analysis)\n",
        "# We will set time to a wildcard to get all the data available over time\n",
        "query_params = {\n",
        "    \"buildstatus\": \"all\",\n",
        "    \"geography\": \"E06000001\",\n",
        "    \"housesalesandprices\": \"median\",\n",
        "    \"month\": \"dec\",\n",
        "    \"propertytype\": \"all\",\n",
        "    \"time\": \"*\"\n",
        "    }\n",
        "\n",
        "\n",
        "# Call function to print pandas df\n",
        "ONS_API_HPI = retrieve_ONS_API_data(dataset_id, ONS_base_url, query_params, version, edition)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imBZEnH5PdOY",
        "outputId": "81a1fa11-93a3-4f31-d606-babe4f9d76d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Request success with status code: 200\n",
            "Request failed with status code: 400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "labour-market"
      ],
      "metadata": {
        "id": "NNVKFMD8Ui8s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the base URL\n",
        "ONS_base_url = \"https://api.beta.ons.gov.uk/v1\"\n",
        "\n",
        "# Assuming we are only going to get time series (based on the nature of the analysis)\n",
        "# We will set time to a wildcard to get all the data available over time\n",
        "query_params = {\"sex\" : \"all-adults\",\n",
        "                \"time\" : \"*\",\n",
        "                \"unitofmeasure\": \"levels\",\n",
        "                \"seasonaladjustment\": \"seasonal-adjustment\",\n",
        "                \"geography\" : \"K02000001\",\n",
        "                \"economicactivity\" : 'unemployed',\n",
        "                \"agegroups\" : '16+'\n",
        "    }\n",
        "\n",
        "\n",
        "# Call function to print pandas df\n",
        "ONS_API_labour_market = retrieve_ONS_API_data(dataset_id, ONS_base_url, query_params, version, edition)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "js__wvwQUjKI",
        "outputId": "3eadfbf3-1e32-4223-c0ee-f5d384dea266"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Request success with status code: 200\n",
            "Request failed with status code: 400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Life expectancy"
      ],
      "metadata": {
        "id": "m0_FyZaFe63l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the base URL\n",
        "ONS_base_url = \"https://api.beta.ons.gov.uk/v1\"\n",
        "\n",
        "# Assuming we are only going to get time series (based on the nature of the analysis)\n",
        "# We will set time to a wildcard to get all the data available over time\n",
        "query_params = {\"agegroups\" : \"30-34\",\n",
        "                \"time\" : \"*\",\n",
        "                \"sex\": \"female\",\n",
        "                \"geography\" : \"E06000001\"\n",
        "    }\n",
        "\n",
        "\n",
        "# Call function to print pandas df\n",
        "ONS_API_life_exp = retrieve_ONS_API_data(dataset_id, ONS_base_url, query_params, version, edition)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LuLE1ElfCYj",
        "outputId": "61cf3d12-c39a-44c7-90e0-34d56cca2d0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Request success with status code: 200\n",
            "Retrieved data:\n",
            "       Date   Data\n",
            "0   2006-08  50.18\n",
            "1   2009-11  51.57\n",
            "2   2001-03   49.2\n",
            "3   2004-06  49.57\n",
            "4   2010-12  51.89\n",
            "5   2012-14  52.15\n",
            "6   2017-19  51.66\n",
            "7   2002-04  49.24\n",
            "8   2008-10  51.44\n",
            "9   2007-09  50.66\n",
            "10  2003-05  49.49\n",
            "11  2005-07  49.61\n",
            "12  2011-13  51.89\n",
            "13  2013-15  51.85\n",
            "14  2016-18  51.76\n",
            "15  2015-17  51.75\n",
            "16  2014-16  51.82\n"
          ]
        }
      ]
    }
  ]
}